{
  "cells": [
    {
      "cell_type": "code",
      "id": "faKFJ8sCLC9KQUllZQZyXYhJ",
      "metadata": {
        "tags": [],
        "id": "faKFJ8sCLC9KQUllZQZyXYhJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "be98df73-cd45-4141-d6cb-8d2b0abbf813"
      },
      "source": [
        "# Script to load FAQ file for use in RAG runtime\n",
        "\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Load CSV to BigQuery\n",
        "\n",
        "# --- Configuration ---\n",
        "gcs_uri = \"gs://labs.roitraining.com/aurora-bay-faqs/aurora-bay-faqs.csv\"\n",
        "dataset_id = \"rag_challenge\"\n",
        "table_id = \"aurora_bay_faqs\"\n",
        "\n",
        "# GCP Details\n",
        "project_id = \"qwiklabs-gcp-03-28c3125acb2b\"\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "# Initialize the BigQuery client\n",
        "client = bigquery.Client()\n",
        "\n",
        "# Construct the full table ID string\n",
        "table_id_full = f\"{client.project}.{dataset_id}.{table_id}\"\n",
        "\n",
        "# --- Load Job Configuration ---\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    source_format=bigquery.SourceFormat.CSV,\n",
        "    skip_leading_rows=1,  # Assuming your CSV has a header row\n",
        "    autodetect=True,      # Let BigQuery automatically infer the schema\n",
        "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
        ")\n",
        "\n",
        "# --- Start the Load Job ---\n",
        "print(f\"Starting load job for '{gcs_uri}' into '{table_id_full}'...\")\n",
        "\n",
        "load_job = client.load_table_from_uri(\n",
        "    gcs_uri,\n",
        "    table_id_full,\n",
        "    job_config=job_config,\n",
        ")  # API request\n",
        "\n",
        "# Wait for the job to complete\n",
        "load_job.result()\n",
        "\n",
        "print(\"Load job finished.\")\n",
        "\n",
        "# Load files\n",
        "try:\n",
        "    destination_table = client.get_table(table_id_full)\n",
        "    print(f\"Loaded {destination_table.num_rows} rows into {table_id_full}.\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not get table details after load: {e}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting load job for 'gs://labs.roitraining.com/aurora-bay-faqs/aurora-bay-faqs.csv' into 'qwiklabs-gcp-03-28c3125acb2b.rag_challenge.aurora_bay_faqs'...\n",
            "Load job finished.\n",
            "Loaded 50 rows into qwiklabs-gcp-03-28c3125acb2b.rag_challenge.aurora_bay_faqs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SQL scripts used to generate embeddings in BQ (This block contains SQL queries directly run in BQ)\n",
        "\n",
        "#SQL Used in BQ\n",
        "\n",
        "#0: Note that I did have to run an alter statement to make the two column headers question & answer\n",
        "\n",
        "#1:\n",
        "#CREATE OR REPLACE MODEL `rag_challenge.embeddings_model`\n",
        "#REMOTE WITH CONNECTION `us.vertex-rag-connection`\n",
        "#OPTIONS (ENDPOINT = 'text-embedding-005');\n",
        "\n",
        "#2:\n",
        "#CREATE OR REPLACE TABLE `rag_challenge.auror_bay_faqs_with_embeddings` AS\n",
        "#SELECT *\n",
        "#FROM ML.GENERATE_EMBEDDING(\n",
        "#    MODEL `rag_challenge.embeddings_model`,\n",
        "#    (SELECT question, answer, concat(question, answer) AS content FROM `qwiklabs-gcp-03-28c3125acb2b.rag_challenge.aurora_bay_faqs`)\n",
        "#);"
      ],
      "metadata": {
        "id": "PnpKe_60jUN1"
      },
      "id": "PnpKe_60jUN1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG Runtime Script\n",
        "\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import base64\n",
        "\n",
        "def generate_response(user_input, sys_instruction):\n",
        "\n",
        "  client = genai.Client(\n",
        "      vertexai=True,\n",
        "      project=\"qwiklabs-gcp-03-28c3125acb2b\",\n",
        "      location=\"us-central1\",\n",
        "  )\n",
        "\n",
        "  model = \"gemini-2.0-flash-001\"\n",
        "\n",
        "  contents = [\n",
        "    types.Content(\n",
        "      role=\"user\",\n",
        "      parts=[\n",
        "        types.Part.from_text(text = user_input)\n",
        "      ]\n",
        "    )\n",
        "  ]\n",
        "\n",
        "  generate_content_config = types.GenerateContentConfig(\n",
        "    temperature = 1,\n",
        "    top_p = 0.95,\n",
        "    max_output_tokens = 8192,\n",
        "    response_modalities = [\"TEXT\"],\n",
        "    speech_config = types.SpeechConfig(\n",
        "      voice_config = types.VoiceConfig(\n",
        "        prebuilt_voice_config = types.PrebuiltVoiceConfig(\n",
        "          voice_name = \"zephyr\"\n",
        "        )\n",
        "      ),\n",
        "    ),\n",
        "    system_instruction=[types.Part.from_text(text=sys_instruction)],\n",
        "  )\n",
        "\n",
        "  output_string = \"\"\n",
        "\n",
        "  for chunk in client.models.generate_content_stream(\n",
        "    model = model,\n",
        "    contents = contents,\n",
        "    config = generate_content_config,\n",
        "    ):\n",
        "    #print(chunk.text, end=\"\")\n",
        "    output_string = output_string + chunk.text\n",
        "\n",
        "  return output_string\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "  # Inputs\n",
        "  user_input_query = 'How many people live in Aurora Bay?'\n",
        "\n",
        "  # GCP Details\n",
        "  project_id = \"qwiklabs-gcp-03-28c3125acb2b\"\n",
        "  client = bigquery.Client(project=project_id)\n",
        "\n",
        "  # Initialize the BigQuery client\n",
        "  client = bigquery.Client()\n",
        "\n",
        "  # Step 1: Get the Top 5 Matching Results from BQ\n",
        "\n",
        "  # Setup query to get top 5 results from BQ via similarity search, with the Vertex AI model connection generating the embedding of the user input question\n",
        "  query = f\"\"\"\n",
        "  SELECT query.query, base.question, base.answer\n",
        "  FROM VECTOR_SEARCH(\n",
        "    TABLE `qwiklabs-gcp-03-28c3125acb2b.rag_challenge.auror_bay_faqs_with_embeddings`, 'ml_generate_embedding_result',\n",
        "    (\n",
        "    SELECT text_embedding, content AS query\n",
        "    FROM ML.GENERATE_TEXT_EMBEDDING(\n",
        "    MODEL `qwiklabs-gcp-03-28c3125acb2b.rag_challenge.embeddings_model`,\n",
        "    (SELECT @query_text AS content))\n",
        "    ),\n",
        "    top_k => 5, options => '{{\"fraction_lists_to_search\": 0.01}}')\n",
        "  \"\"\"\n",
        "\n",
        "  # Configuration of the user input parameter\n",
        "  job_config = bigquery.QueryJobConfig(\n",
        "    query_parameters = [\n",
        "        bigquery.ScalarQueryParameter(\"query_text\", \"STRING\", user_input_query),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  top5_results_df = client.query(query, job_config=job_config).to_dataframe()\n",
        "\n",
        "  # Step 2: Construct Prompt from the Top 5 Matching Results from BQ\n",
        "  # Construct Prompt\n",
        "  prompt_qnas = \"Please Use the Reference Question And Answers to answer the user's query: \\n\"\n",
        "\n",
        "  for row in top5_results_df.itertuples():\n",
        "      prompt_qnas = prompt_qnas + f\"Question: {row.question}, Answer: {row.answer}\\n\"\n",
        "\n",
        "  # Step 3: Add back in the original user question\n",
        "  final_prompt = prompt_qnas + \"\\nUser Query: \\n\" + user_input_query\n",
        "\n",
        "  #print(final_prompt)\n",
        "\n",
        "  # Step 4: Get Response from Gemini\n",
        "\n",
        "  sys_instructions = \"\"\"You are a helpful FAQ agent who helps answer user questions on the topic of Aurora Bay. An example set of questions will be provided for additional context.\"\"\"\n",
        "  final_rag_results = generate_response(final_prompt, sys_instructions)\n",
        "\n",
        "  print(final_prompt)\n",
        "  print(\"\\n\")\n",
        "  print(final_rag_results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTz1bmQqXvma",
        "outputId": "2b02c0c6-f17a-4bc4-ed0c-24dace48b486"
      },
      "id": "PTz1bmQqXvma",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please Use the Reference Question And Answers to answer the user's query: \n",
            "Question: What is the population of Aurora Bay?, Answer: Aurora Bay has a population of approximately 3,200 residents, although it can fluctuate seasonally due to temporary fishing and tourism workforces.\n",
            "Question: What is the average temperature range in Aurora Bay?, Answer: Winters average between 10°F to 25°F, while summers are milder, around 50°F to 65°F. Temperatures can vary with coastal weather patterns.\n",
            "Question: Who is the current mayor of Aurora Bay?, Answer: The current mayor is Linda Greenwood, elected in 2021 for a four-year term.\n",
            "Question: Is there a local hospital in Aurora Bay?, Answer: Yes. The Aurora Bay Community Hospital offers emergency and routine medical services. It’s located on North Aurora Boulevard.\n",
            "Question: What are the primary industries in Aurora Bay?, Answer: The primary industries include commercial fishing, tourism, and small-scale logging in the nearby forests.\n",
            "\n",
            "User Query: \n",
            "How many people live in Aurora Bay?\n",
            "\n",
            "\n",
            "Aurora Bay has a population of approximately 3,200 residents, although it can fluctuate seasonally due to temporary fishing and tourism workforces.\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "genai_challenge_002_jason_lajeunesse"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}